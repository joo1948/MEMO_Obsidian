안녕하세요. "AI기술 발전이 인간의 일자리를 빼앗는가 ? "를 주제로 발표할 3조 한지은, 송수산나, 강주영입니다.

저희는 "과학은 반역이다"책 내용 발췌 및 의의, AI기술 발전의 역사와 원리에 대한 것과 인간의 영역에 손을 뻗는 AI 사례를 설명하고 마무리 지을 예정입니다.

“부의 분배에 불평등을 강화하는 쪽으로 기술이 발전하거나 삶의 파괴를 더 노골적으로 조장할 때, 흔히들 과학이 쓸모가 있다고 말한다.”

- 고드프리 해럴드 하리(Godfrey Harold Hardy, 영국 수학자)
이는 프리먼 다이슨의 '과학은 반역이다'에서 매우 강경한 견해를 갖고 있떤 그의 스승 고드프리 해럴드 하디의 말입니다.  하디의 발언은 사방에서 전쟁의 포성이 귀청을 찢는 상황에서 나온, 과학에 대한 회의적인 시선을 반영한 것입니다. 많은 사람들에게 일상 속 소소한 편리함과 안정감을 가져다 줄 때보다, 전쟁과 고통의 상황에서 더 열광하는 사람들의 태도를 비판한 말입니다. 
프리먼 다이슨은 이러한 하디의 관점을, 비록 그것이 격동의 시기에서 나온 것이라 할지라도, 평화로운 시기에 한 번쯤 생각해볼 가치가 있다고 이야기하고 있습니다.

과학기술의 발전은 마치 쏜살같이 질주하는 기차에 비유할 수 있습니다. 기차는 멈추지 않고 앞으로 나아가며, 우리 삶의 여러 부분을 혁신하지만 동시에 많은 사람들을 두려움 속에 몰아넣고 있는 것이 현실입니다. 이는 많은 사람에게 새로운 기회를 만들어 주기도 하지만, 길가의 작은 풀들은 미처 생각지 못한 채 무참히 짓밟고 지나가는 것과 마찬가지입니다. 현재 주목받고 있는 AI 기술 또한 이 기차와 같은 양면성을 지니는데,  AI는 산업 구조와 일자리를 혁신하고 우리 삶의 많은 부분을 바꾸고 있습니다. AI 기술 도입은 효율성을 높이고 새로운 기회를 창출할 가능성을 열어주지만, 동시에 많은 사람들의 일자리를 위협하며 경제적 불평등을 심화시킬 수 있다는 우려도 존재한다. 

따라서 AI 기술 발전에 대한 논의는 다양한 측면에서 이루어져야 합니다.  AI가 가져오는 혁신적 변화와 효율성 증대는 긍정적인 가능성을 열어주지만, 그 이면에는 부작용과 사회적 비용도 존재하기 때문입니다. 이러한 맥락에서 AI가 인간의 일자리를 빼앗는 문제는 단순히 기술적 진보의 문제가 아니라, 사회적 정의와 형평성, 그리고 미래의 노동 구조에 관한 문제라고 볼 수 있습니다. ‘과학은 반역이다’에서 저자는 기술의 발전과 노동자 사이의 괴리를 비판적인 시점으로 보고 있습니다.

저자의 시점은 다음 책 속의 발언을 통해 더 구체적으로 알 수 있습니다.

“오늘날 기술은 마치 경쟁하듯 매우 빠르게 공장과 사무실의 노동자들을 대체하고 있다. 또한 주주는 더 부유하게, 노동자는 더 가난하게 만들면서 사실상 불평등한 부의 분배를 가속하고 있다. 게다가 하디가 살았던 시대에 그랬던 것처럼, 오늘날에도 치명적인 무기를 만들어내는 기술들이 돈벌이가 되고 있다.”

3조는 저자가 제시한 기술 발전에 대한 문제 상황을 현대에 새롭게 주목받는 기술, ‘AI’로 확장시켜 논의해보고자 합니다. 특히 AI와 같은 첨단 기술이 인간의 일자리에 미치는 영향을 보면, 과학기술은 단순히 발전 그 이상의 의미를 지닌다는 것을 알 수 있습니다. 이 글에서는 AI 기술 발전이 가져온 일자리 문제에 대한 사례와 논쟁을 살펴보고, 그 논쟁의 핵심 쟁점을 분석하고자 합니다. 먼저 AI의 발전 과정과 원리에 대해 간략히 설명하고, 실제 사례를 통해 사회적 양상을 살펴보며, 찬반 논쟁을 다룸으로써 과학과 사회 사이의 무게중심을 어떻게 잡아야 하는가를 함께 논의하고자 합니다. 이러한 논의는 앞으로 더 발전해나갈 AI에 대해 우리가 어떤 태도를 취해야 하며, 기술의 발전이 사회에 긍정적인 영향을 미칠 수 있도록 어떠한 방향으로 나아가야 할지를 함께 생각해보는 것에 의의가 있습니다.


====


AI가 주목받기 시작한 시점은 지금으로부터 멀지 않습니다.  AI의 시작은 1950년대로 거슬러 올라가볼 수 있는데, 1950년, 영국의 수학자 앨런 튜링(Alan Turing)은 기계는 생각할 수 있다고 주장하며, 이를 테스트하기 위한 방법으로 ‘튜링 테스트(The Turing Test)’를 고안했습니다. 이는 AI라는 개념을 최초로 제시한 연구로 꼽힙니다. 1956년에는 AI의 개념을 세상에 알린 다트머스 회의(Dartmouth Conference)가 열렸다. 이 회의에서는 기계가 인간처럼 학습하고 발전할 수 있는지에 대한 토론이 이루어졌으며, 이때 인공지능이라는 용어가 처음 사용되었다. 인공이라는 개념이 생겨난 이후, 100년도 채 지나지 않은 현시점에서 우리는 인공지능이 제공하는 수많은 이점을 일상에서 느끼고 있습니다. 특히 현재 일반인들도 쉽게 사용 가능한 생성형 AI(Generative AI), 챗봇(ChatGPT)은 이전에는 상상도 하지 못한 편리함을 가져다 줍니다.

AI의 원리를 간략하게 6가지의 과정으로 정리할 수 있는데, 첫 단계는 '데이터'입니다. 데이터를 많이 수집하는 것이 핵심인데, AI가 뭔가를 배우기 위해서는 그 주제에 대한 다양한 정보가 필요하기 때문입니다. 예를 들어, 강아지를 인식하는 AI를 만들려면, 수많은 강아지 사진을 모아야 힙니다. 이렇게 다양한 데이터를 수집해 AI에게 학습할 기초 자료를 제공하고, 수집한 데이터는 결과는 깔끔하지 않다. 사진에 강아지가 보이지 않거나 너무 흐릿한 경우가 있을 수 있습니다. 그래서 우리는 데이터를 정리하고, 필요 없는 정보는 제거하는 작업을 해야 합니다. 이를 '데이터 전처리'라고 합니다. 2 단계에서는 데이터가 정확하고 학습에 도움이 되도록 준비하는 데이터 전처리 작업을 합니다 .준비를 마쳤으면, AI가 학습을 하는 데 필요한 '모델'이라는 것을 선택해야 합니다. 모델은 일종의 수학적인 공식이나 규칙이라고 생각하면 되는데, 다양한 종류의 AI 모델이 있으며, 문제의 성격에 따라 적합한 모델을 선택하게 된다. 예를 들어, 이미지 인식을 위한 모델과 텍스트를 이해하는 모델은 다릅니다. 모델을 선택한 후에는 AI가 수집한 데이터를 바탕으로 학습을 시작하고. 학습한 데이터를 이용해 모델이 규칙을 익히고, 패턴을 파악하는 과정을 거칩니다. 해당 단계에서 모델은 많은 데이터를 반복적으로 분석하고 그 안에서 공통적인 특징을 찾아냅니다. 예를 들어, 강아지 사진 수천 장을 보고 나서 '강아지'라는 것이 어떻게 생겼는지 이해하는 것입니다. 이후에 모델이 잘 학습했는지 확인하는 과정이 필요하한데, 이를 위해 새로운 데이터를 이용해 모델을 검증합니다. 이 데이터는 학습할 때 사용하지 않은 데이터여야 하며, 이를 통해 모델이 새로운 데이터를 잘 이해하고 있는지 확인할 수 있습니다. 예를 들어, 강아지 사진을 AI에게 보여주고 제대로 강아지라고 인식하는지 평가하는 것입니다. 학습과 검증이 끝난 후에는 AI는 학습된 내용을 바탕으로 새로운 데이터를 입력받아 결과를 예측할 수 있습니다. 예를 들어, 새로운 동물 사진을 보여주면, AI가 이것이 강아지인지 아닌지 예측합니다.

=================
AI 기술의 발전은 마치 거대한 파도처럼 우리 삶의 다양한 영역을 휩쓸며 변화를 일으키고 있습니다. 할리우드 작가 파업과 KB국민은행 콜센터 해고 사태는 그 물결의 일부분일 뿐입니다. 이 흐름은 효율성과 혁신이라는 긍정적인 에너지를 실어오지만, 그 이면에는 일자리 상실과 같은 예상치 못한 소용돌이도 함께 동반합니다. 이는 단순히 기술의 진보가 아니라, 사회적 구조와 인간 삶의 본질에 대한 재고를 요구하는 중요한 시점임을 시사합니다

우리는 이러한 흐름 속에서 방향을 잃지 않기 위해서는 항해의 나침반, 즉 사회적 합의와 윤리적 기준이 필요합니다. 기술의 발전은 불가피하지만, 그로 인한 불평등과 갈등을 최소화하기 위한 제도적 장치와 사회적 안전망이 마련되지 않으면, 이 물결은 파괴적 힘으로 작용할 수 있다는 것입니다. AI 기술은 단순히 효율성을 위한 도구가 아니라, 인간의 돕는 범위 안에서 삶을 풍요롭게 하는 수단이 되어야 한다는 것입니다.

AI의 도입은 기업에게 효율성과 비용 절감이라는 긍정적인 변화를 제공하지만, 이로 인해 일자리를 잃는 노동자들에게는 생계 위협과 사회적 불안정이라는 부정적인 결과를 초래할 수 있습니다. AI 기술이 단순히 기술적 혁신에 그치는 것이 아니라, 인간의 존엄성과 사회적 정의를 고려하는 방식으로 활용되어야 한다는 점에서 이 논의는 중요한 의미를 가집니다.

따라서 우리는 기술 발전의 속도에만 초점을 맞추는 것이 아니라, 그에 따른 사회적 책임과 윤리적 문제를 함께 고민해야 합니다. AI 기술이 가져올 변화에 대비하여 사회적 안전망과 노동자의 재교육 및 재취업 지원이 필요하며, 이를 통해 AI가 인간과 협력하며 공존할 수 있는 환경을 조성하는 것이 중요합니다. 이러한 논의는 AI 시대를 준비하는 우리 사회가 더 공정하고 포용적인 방향으로 나아갈 수 있는 길잡이가 될 것이라 예상합니다.

이상으로 발표를 마치겠습니다.

감사합니다.



