### [국내 사례]
1. **"AI 도입으로 인한 택시·배달업계 갈등"**
	[배경]
	- **AI 배차 시스템 도입:** 배달 플랫폼과 택시 업계에서 AI 기반의 배차 시스템을 도입하여 서비스 효율성을 높이고자 했습니다. 이러한 시스템은 주문과 차량 또는 배달원을 최적화하여 매칭함으로써 고객 대기 시간을 줄이고 운영 효율을 높입니다.
	[문제발생]
	- **배달료 및 수익 감소:** AI 배차 시스템이 도입되면서 배달원과 택시 기사들의 수익이 감소하는 현상이 나타났습니다. 이는 AI가 수요와 공급을 실시간으로 분석하여 배차를 최적화하면서, 개별 노동자들의 업무량과 수익에 영향을 미쳤기 때문입니다.
	- **배달료 하락:** AI가 배차를 효율적으로 조정함에 따라 배달 시간이 단축되고, 한 명의 배달원이 처리할 수 있는 주문량이 늘어났습니다. 그러나 이는 전체적인 배달료의 하락으로 이어져 배달원들의 수익이 감소했습니다.
	- **택시 요금 문제:** 택시 업계에서도 AI 기반 요금 정책이 도입되면서 승객들에게는 요금 인하 혜택이 있었지만, 택시 기사들의 수입은 감소했습니다.
	[노동자들의 반발]
	- **시위와 항의:** 수익 감소에 직면한 배달원들과 택시 기사들은 플랫폼 기업의 일방적인 정책 변경에 반발하여 시위와 항의 활동을 전개했습니다.
		- **노동 조건 악화 주장:** 노동자들은 AI 도입이 자신들의 노동 강도는 높이고 수익은 줄이는 방향으로 작용하고 있다고 주장했습니다.
		- **의사소통 부족:** 플랫폼 기업과 노동자 간의 충분한 소통 없이 정책이 시행되어 불만이 증폭되었습니다.
- 출처 : 
	- 한국경제신문 (2023년 3월 15일), "AI 배차 도입했더니... 배달료 뚝뚝 떨어졌다"
	-  **기사:** 경향신문 (2020년 7월 20일), "배달 라이더들, AI 배차 시스템에 '인간 대우' 요구"
    
	- **논문:** 김혜진 (2021). "플랫폼 노동과 알고리즘 통제: 배달 라이더의 노동 경험을 중심으로." _노동사회연구_, 50, 27-58.
- 적절한 이유
	- **AI 발전과 불평등의 직접적인 연관성:** AI 도입이 노동자들의 수익 감소와 노동 조건 악화로 이어져 불평등을 심화시키는 구체적인 사례입니다.
    
	- **정부 개입의 필요성 부각:** 노동자들의 권익 보호와 공정한 수익 분배를 위해 정부의 규제와 정책 개입이 필요한 상황을 보여줍니다.
    
	- **현실적인 갈등 상황 제시:** 국내에서 실제로 발생한 갈등 사례로서 토론 주제에 현실감을 더해줍니다.

2. **"인공지능 면접 도입으로 인한 취업 불평등 논란"**
	- **AI 면접의 도입:** 국내 대기업과 공기업에서 **인공지능 면접 시스템**을 도입하여 채용 과정을 자동화하고 있습니다. AI 면접은 지원자의 표정, 음성, 언어 등을 분석하여 역량과 성향을 평가합니다.
	 [불평등 심화 우려]
		 - **편향성 문제:** AI 알고리즘이 학습한 데이터에 편향이 있을 경우 특정 계층이나 성별, 연령대에 불리한 결과를 초래할 수 있습니다.
		 - **접근성 문제:** AI 면접에 익숙하지 않은 지원자나 디지털 환경에 취약한 계층은 상대적으로 불리할 수 있습니다.
		 - **심리적 부담:** 비대면 환경에서 AI와의 면접은 지원자들에게 추가적인 스트레스를 유발할 수 있습니다.
- 출처
	- **기사:** 조선일보 (2020년 9월 21일), "인공지능 면접에 떨고 있는 취준생들"
	- **논문:** 김동원, 박수진 (2021). "인공지능 면접의 공정성에 관한 연구." _인사관리연구_, 45(2), 67-89.
- 적절한 이유
	- **정부 개입의 필요성:** 채용 과정의 공정성과 평등을 보장하기 위해 정부가 AI 면접 시스템의 **표준화**, **편향성 검증** 등의 규제를 마련할 필요가 있습니다.

3. **"AI 챗봇 '이루다' 서비스 중단 사태"**
	- **이루다의 등장과 문제 발생:** 스캐터랩에서 개발한 AI 챗봇 **'이루다'** 는 자연스러운 대화로 큰 주목을 받았지만, 서비스 과정에서 **성차별적 발언**과 **개인정보 유출** 문제가 발생했습니다.
	[**사회적 논란:**]
	- **윤리적 문제:** 이루다가 혐오 표현을 사용하고, 학습 데이터로 사용된 실제 개인의 대화 내용이 유출되어 **프라이버시 침해** 논란이 일어났습니다.
    - **서비스 중단:** 사회적 비판이 거세지자 이루다 서비스는 중단되었고, AI 윤리에 대한 논의가 촉발되었습니다.
- 출처 
	- - **기사:** 연합뉴스 (2021년 1월 12일), "AI 챗봇 '이루다' 서비스 중단…개발사 '심려 끼쳐 죄송'"
    - **논문:** 박지훈 (2021). "AI 챗봇 이루다 사태를 통해 본 인공지능 윤리와 법적 과제." _정보법학연구_, 25(2), 89-115.
- 적절한 이유
	- **정부 개입의 필요성:** AI 서비스의 **윤리적 기준**과 **개인정보 보호**를 위한 규제 강화의 필요성을 보여줍니다.

### [해외사례 - 토론]
4. "**유럽연합(EU)의 AI 규제안 제안**"
	- [배경]
		- 유럽연합(EU)은 인공지능(AI) 기술의 발전이 사회, 경제, 윤리적 측면에서 큰 영향을 미칠 수 있다는 인식 하에, AI의 개발과 활용에 대한 포괄적인 규제 프레임워크를 마련하고자 했습니다. 이에 따라 2021년 4월 21일에 '인공지능 법(AI Act)' 초안을 발표했습니다. 이 법안은 세계 최초로 AI를 종합적으로 규제하려는 시도로 주목받았습니다.
	- **위험 기반 접근법(Risk-based approach):**
	    - **금지된 AI 관행(Prohibited AI Practices):** 인간의 안전과 기본권에 심각한 위협을 가하는 AI 시스템은 전면 금지됩니다.
	        - 예: 실시간 원격 생체 인식(공공장소에서의 얼굴 인식), 무의식적 행동을 조작하는 시스템, 사회 신용 점수화 시스템 등.
	    - **고위험 AI 시스템(High-risk AI Systems):**
	        - **분야:** 의료, 교통, 법 집행, 교육, 취업, 금융 등.
	        - **요구사항:** 엄격한 데이터 거버넌스, 문서화, 투명성, 인간 감독, 정확성, 사이버 보안 등을 준수해야 합니다.
	    - **제한된 위험의 AI 시스템(Limited-risk AI Systems):**
	        - **투명성 요구사항:** 챗봇이나 딥페이크 등 사용자는 AI와 상호작용하고 있음을 인지할 수 있어야 합니다.
	    - **최소 위험의 AI 시스템(Minimal-risk AI Systems):**
	        - **규제 없음:** 대부분의 AI 시스템이 이에 해당하며, 규제 없이 자유롭게 개발 및 사용 가능합니다.
	- **투명성 및 인간 감독 강화:**
	    - AI 시스템의 작동 방식과 목적에 대한 명확한 정보 제공.
	    - 중요한 의사결정 과정에서 인간의 개입과 감독을 보장.
	- **시장 감시 및 집행:**
	    - 각 회원국은 규제 준수를 감시하는 시장 감시 기관을 지정.
	    - 위반 시 최대 매출액의 6% 또는 3,000만 유로까지의 벌금 부과 가능.
- 출처 : 
	- European Commission (2021). "Proposal for a Regulation Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act)."
    
	    - [https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206)
	- European Parliament (2023). "Artificial Intelligence Act: Parliament adopts negotiating position."
    
	    - [https://www.europarl.europa.eu/news/en/press-room/20230609IPR96515/artificial-intelligence-act-parliament-adopts-negotiating-position-on-first-eu-rules](https://www.europarl.europa.eu/news/en/press-room/20230609IPR96515/artificial-intelligence-act-parliament-adopts-negotiating-position-on-first-eu-rules)
	- OECD AI Policy Observatory.
    
	    - https://oecd.ai/en
- 적절한 이유
	- **균형 잡힌 접근법:** 혁신을 촉진하면서도 기본권을 보호하기 위한 규제 프레임워크를 제시합니다.
    
	- **국제 표준 설정:** EU의 규제는 글로벌 기업들이 준수해야 하는 기준이 될 수 있으며, 이는 AI 기술의 책임 있는 개발을 촉진합니다.

5. **"세계경제포럼(WEF) 연례 회의에서의 "인공지능과 불평등" 패널 토론"**
	[**토론 내용:**]
		-  **AI가 경제와 노동 시장에 미치는 영향:**
		    - **일자리 대체 우려:** 인공지능과 자동화로 인해 단순 노동 및 반복 업무가 대체되어 대량 실업이 발생할 수 있다는 우려가 제기되었습니다.
		    - **기술 격차:** 고숙련 노동자와 저숙련 노동자 간의 소득 격차가 더욱 벌어질 수 있음이 논의되었습니다.
		-  **사회적 불평등 심화:**
			- **디지털 격차:** AI 기술에 대한 접근성이 부족한 개발도상국이나 취약 계층은 더욱 뒤처질 수 있다는 점이 강조되었습니다.
		    - **부의 편중:** AI 기술을 소유하거나 개발하는 기업과 국가에 부가 집중될 수 있음이 지적되었습니다.
		- **정부의 역할과 개입 필요성:**
		    - **교육과 재훈련:** 정부는 노동자들이 새로운 기술에 적응할 수 있도록 교육 및 재훈련 프로그램을 지원해야 한다는 의견이 나왔습니다.
		    - **정책적 대응:** 사회 안전망 강화, 공정한 세제 정책, 기술 규제 등을 통해 불평등을 완화해야 한다는 주장이 제기되었습니다.
		    - **글로벌 협력:** AI로 인한 도전 과제는 국제적인 협력이 필요하며, 정부 간 협의를 통해 해결 방안을 모색해야 한다는 의견이 있었습니다.
		- **기업의 책임:**
		    - **윤리적 AI 개발:** 기업들은 AI 기술 개발 시 윤리적 기준을 준수하고, 사회적 책임을 다해야 한다는 논의가 있었습니다.
		    - **포용적 성장 촉진:** 기업들은 기술 혁신의 혜택이 모든 사람들에게 돌아갈 수 있도록 노력해야 한다는 점이 강조되었습니다.
- 출처
	- - **세계경제포럼 공식 웹사이트:**
	    - 토론 영상 및 요약: WEF Annual Meeting 2018 - The Global Impact of AI
	- **관련 기사:**
    - BBC News (2018년 1월 25일), "[Davos 2018: Will robots steal our jobs?](https://www.bbc.com/news/business-42812341)"
    - The Guardian (2018년 1월 24일), "[Technology CEOs sound warning on AI's unintended consequences](https://www.theguardian.com/technology/2018/jan/24/technology-ceos-warn-on-ai-unintended-consequences-davos)"
- 적절한 이유
	- **정부 개입 논의의 직접적인 사례:**
	    - 이 토론회에서는 AI 발전으로 인한 불평등 심화에 대해 정부가 어떤 역할을 해야 하는지에 대한 다양한 관점이 제시되었습니다.
	- **글로벌 리더들의 견해 제공:**
	    - 주요 기업의 CEO와 정책 입안자들이 참여하여 현실적인 문제점과 해결책에 대한 심도 있는 논의를 했습니다.
	- **다양한 분야의 의견 수렴:**
	    - 경제, 기술, 정책 분야의 전문가들이 참여하여 다각적인 시각에서 문제를 분석하였습니다.